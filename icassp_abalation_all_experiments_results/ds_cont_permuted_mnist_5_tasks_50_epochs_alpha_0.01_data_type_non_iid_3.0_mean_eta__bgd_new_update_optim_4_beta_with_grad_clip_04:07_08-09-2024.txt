****************************************************************************************************
Writing results to ds_cont_permuted_mnist_5_tasks_50_epochs_alpha_0.01_data_type_non_iid_3.0_mean_eta__bgd_new_update_optim_4_beta_with_grad_clip_04:07_08-09-2024
Arguments are Namespace(dataset='ds_cont_permuted_mnist', nn_arch='mnist_simple_net_200width_domainlearning_784input_10cls_1ds', logname='continous_permuted_mnist_5_tasks', results_dir='ds_cont_permuted_mnist_5_tasks_50_epochs_alpha_0.01_data_type_non_iid_3.0_mean_eta__bgd_new_update_optim_4_beta_with_grad_clip_04:07_08-09-2024', seed=1000, num_workers=8, num_epochs=50, batch_size=128, pruning_percents=[], train_mc_iters=10, std_init=0.05, mean_eta=3.0, permanent_prune_on_epoch=-1, permanent_prune_on_epoch_percent=90, momentum=0.9, lr=0.01, weight_decay=0.0005, test_freq=1, contpermuted_beta=4, optimizer='bgd_new_update', optimizer_params='{}', inference_mc=False, inference_map=True, inference_committee=False, inference_aggsoftmax=False, inference_initstd=False, committee_size=0, test_mc_iters=0, init_params=['{"bias_type":', '"xavier",', '"conv_type":', '"xavier",', '"bn_init":', '"01"}'], desc='', bw_to_rgb=False, permuted_offset=False, labels_trick=False, num_of_permutations=4, iterations_per_virtual_epc=67, separate_labels_space=False, permute_seed=2019, federated_learning=True, n_clients=5, num_aggs_per_task=1, grad_clip=True, max_grad_norm=1.0, non_iid_split=True, alpha=0.01, alpha_mg=0.1)
########################## 
######### Round 1 complete ######### 
####### Round No. - 1, Task No. - 0 #########
Client-wise [loss, accuracy] accuracies bgd_new_update_optim after all rounds are {'0': [[2.729], [8.92]], '1': [[2.601], [13.7]], '2': [[2.483], [10.53]], '3': [[2.624], [12.35]], '4': [[2.481], [13.26]]}
############################# 
######### Round 2 complete ######### 
####### Round No. - 2, Task No. - 1 #########
Client-wise [loss, accuracy] accuracies bgd_new_update_optim after all rounds are {'0': [[2.4, 2.102], [14.06, 22.88]], '1': [[2.863, 2.323], [10.32, 15.7]], '2': [[2.993, 2.741], [9.55, 10.24]], '3': [[3.55, 2.538], [8.92, 8.98]], '4': [[3.311, 2.783], [9.86, 18.27]]}
############################# 
######### Round 3 complete ######### 
####### Round No. - 3, Task No. - 2 #########
Client-wise [loss, accuracy] accuracies bgd_new_update_optim after all rounds are {'0': [[3.534, 3.507, 3.449], [9.74, 9.8, 9.79]], '1': [[2.904, 2.857, 2.377], [9.02, 10.23, 14.3]], '2': [[5.69, 5.153, 5.582], [9.58, 10.03, 18.47]], '3': [[3.121, 2.943, 2.417], [11.42, 11.56, 21.94]], '4': [[3.095, 2.715, 2.227], [10.23, 13.41, 22.51]]}
############################# 
######### Round 4 complete ######### 
####### Round No. - 4, Task No. - 3 #########
Client-wise [loss, accuracy] accuracies bgd_new_update_optim after all rounds are {'0': [[5.514, 6.225, 5.933, 5.336], [11.94, 13.79, 18.38, 19.74]], '1': [[16.65, 16.27, 16.344, 16.427], [10.31, 10.32, 13.54, 10.63]], '2': [[439.925, 427.736, 452.319, 363.918], [8.92, 8.92, 8.92, 9.79]], '3': [[6.631, 6.345, 6.248, 6.052], [10.27, 11.69, 9.89, 17.24]], '4': [[5.102, 5.004, 4.743, 4.557], [10.02, 14.99, 16.81, 13.14]]}
############################# 
######### Round 5 complete ######### 
####### Round No. - 5, Task No. - 4 #########
Client-wise [loss, accuracy] accuracies bgd_new_update_optim after all rounds are {'0': [[274.433, 272.163, 274.471, 273.223, 296.145], [10.28, 11.35, 11.62, 18.46, 20.77]], '1': [[21274.006, 21263.318, 21275.995, 21222.669, 21132.225], [9.82, 9.82, 9.82, 9.81, 14.27]], '2': [[70.67, 70.525, 66.963, 67.794, 34.631], [7.78, 14.71, 17.59, 17.38, 17.7]], '3': [[20897.168, 20897.425, 20897.272, 20897.208, 20897.947], [9.69, 9.74, 9.74, 9.72, 16.99]], '4': [[123.109, 123.179, 122.853, 122.635, 124.357], [9.8, 9.8, 10.64, 9.8, 22.44]]}
############################# 
Task-wise accuracies bgd_new_update_optim after all rounds are [[8.12], [12.56, 21.51], [9.89, 22.98, 30.03], [8.92, 8.92, 8.92, 8.92], [9.82, 9.82, 9.82, 9.82, 9.82]]
Task-wise losses bgd_new_update_optim after all rounds are [[2.438], [2.394, 2.195], [2.716, 2.518, 2.301], [83.506, 81.869, 82.561, 80.674], [8559.822, 8559.075, 8560.17, 8557.782, 8554.589]]
Average accuracies bgd_new_update_optim after all rouds are [8.12, 17.035, 20.967, 8.92, 9.82]
Average losses bgd_new_update_optim after all rouds are [2.438, 2.295, 2.512, 82.152, 8558.287]
