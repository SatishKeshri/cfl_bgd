running with abalation!! Are you sure?
[2024-09-07 22:37:44 Info] Script args: Namespace(dataset='ds_cont_permuted_mnist', nn_arch='mnist_simple_net_200width_domainlearning_784input_10cls_1ds', logname='continous_permuted_mnist_5_tasks', results_dir='ds_cont_permuted_mnist_5_tasks_50_epochs_alpha_0.01_data_type_non_iid_3.0_mean_eta__bgd_new_update_optim_4_beta_with_grad_clip_04:07_08-09-2024', seed=1000, num_workers=8, num_epochs=50, batch_size=128, pruning_percents=[], train_mc_iters=10, std_init=0.05, mean_eta=3.0, permanent_prune_on_epoch=-1, permanent_prune_on_epoch_percent=90, momentum=0.9, lr=0.01, weight_decay=0.0005, test_freq=1, contpermuted_beta=4, optimizer='bgd_new_update', optimizer_params='{}', inference_mc=False, inference_map=True, inference_committee=False, inference_aggsoftmax=False, inference_initstd=False, committee_size=0, test_mc_iters=0, init_params=['{"bias_type":', '"xavier",', '"conv_type":', '"xavier",', '"bn_init":', '"01"}'], desc='', bw_to_rgb=False, permuted_offset=False, labels_trick=False, num_of_permutations=4, iterations_per_virtual_epc=67, separate_labels_space=False, permute_seed=2019, federated_learning=True, n_clients=5, num_aggs_per_task=1, grad_clip=True, max_grad_norm=1.0, non_iid_split=True, alpha=0.01, alpha_mg=0.1)
[2024-09-07 22:37:44 Info] Computer name: iiitd with pytorch version: 2.0.1
Dataset is  ds_cont_permuted_mnist
[2024-09-07 22:37:44 Info] Arguments are Namespace(dataset='ds_cont_permuted_mnist', nn_arch='mnist_simple_net_200width_domainlearning_784input_10cls_1ds', logname='continous_permuted_mnist_5_tasks', results_dir='ds_cont_permuted_mnist_5_tasks_50_epochs_alpha_0.01_data_type_non_iid_3.0_mean_eta__bgd_new_update_optim_4_beta_with_grad_clip_04:07_08-09-2024', seed=1000, num_workers=8, num_epochs=50, batch_size=128, pruning_percents=[], train_mc_iters=10, std_init=0.05, mean_eta=3.0, permanent_prune_on_epoch=-1, permanent_prune_on_epoch_percent=90, momentum=0.9, lr=0.01, weight_decay=0.0005, test_freq=1, contpermuted_beta=4, optimizer='bgd_new_update', optimizer_params='{}', inference_mc=False, inference_map=True, inference_committee=False, inference_aggsoftmax=False, inference_initstd=False, committee_size=0, test_mc_iters=0, init_params=['{"bias_type":', '"xavier",', '"conv_type":', '"xavier",', '"bn_init":', '"01"}'], desc='', bw_to_rgb=False, permuted_offset=False, labels_trick=False, num_of_permutations=4, iterations_per_virtual_epc=67, separate_labels_space=False, permute_seed=2019, federated_learning=True, n_clients=5, num_aggs_per_task=1, grad_clip=True, max_grad_norm=1.0, non_iid_split=True, alpha=0.01, alpha_mg=0.1)
Took 99.0% of the P-MNSIT dataset
Took 99.0% of the P-MNSIT dataset
Took 99.0% of the P-MNSIT dataset
Took 99.0% of the P-MNSIT dataset
Took 99.0% of the P-MNSIT dataset
round_end_iters list [ 837 1507 2177 2847 3350]
[ 837 1507 2177 2847 3350]
5
Client Indices Generation starts
Non-IID split is happening and alpha is 0.01
Non-IID split is happening and alpha is 0.01
Non-IID split is happening and alpha is 0.01
Non-IID split is happening and alpha is 0.01
Non-IID split is happening and alpha is 0.01
Clients Indices Generation ends
Client Indices Generation took 76.97977209091187 seconds
1
[2024-09-07 22:39:02 Info] Transformed model to CUDA
[2024-09-07 22:39:02 Info] Initialized 0 Conv2d layers using nn.init.xavier_normal_
[2024-09-07 22:39:02 Info] Initialized 3 linear layers using xavier
[2024-09-07 22:39:02 Info] Initialized 0 bias conv2d layers using nn.init.xavier.noraml_
[2024-09-07 22:39:02 Info] Initialized 3 bias linear layers using xavier
[2024-09-07 22:39:02 Info] Initialized 0 BN layers using weight=1 and bias=0
[2024-09-07 22:39:02 Info] BGD params: {'mean_eta': 3.0, 'std_init': 0.05, 'mc_iters': 10, 'alpha_mg': 0.1}
It's here in new bgd optimizer
0
[2024-09-07 22:39:02 Info] Inference method: {'map'}
[2024-09-07 22:39:02 Info] Number of parameters in the model is 199,210
[2024-09-07 22:39:02 Info] Criterion parameters: type=<class 'torch.nn.modules.loss.CrossEntropyLoss'>
[2024-09-07 22:39:02 Info] BGD params: {'mean_eta': 3.0, 'std_init': 0.05, 'mc_iters': 10, 'alpha_mg': 0.1}
It's here in new bgd optimizer
[2024-09-07 22:39:02 Info] Gradient clipping with max_norm being done
Model id is  139714763863888
Model value at client 1 is 19.580320358276367 in round 1
[2024-09-07 22:39:02 Info] Training epoch number 1 with dataset number 0
[2024-09-07 22:39:10 Info] Client id 0, Epoch 1, train set, Iter 500 current average loss 0.9323
[2024-09-07 22:39:16 Info] Running test set for epoch number 1 for dataset idx 0 using map
[2024-09-07 22:39:16 Info] Stats for test [map] set of size 10000, loss is 2.7293, acc is 8.92%
[2024-09-07 22:39:16 Info] Running test set for epoch number 1 for dataset idx 1 using map
[2024-09-07 22:39:17 Info] Stats for test [map] set of size 10000, loss is 3.0611, acc is 21.04%
[2024-09-07 22:39:17 Info] Running test set for epoch number 1 for dataset idx 2 using map
[2024-09-07 22:39:17 Info] Stats for test [map] set of size 10000, loss is 2.777, acc is 8.93%
[2024-09-07 22:39:17 Info] Running test set for epoch number 1 for dataset idx 3 using map
[2024-09-07 22:39:18 Info] Stats for test [map] set of size 10000, loss is 2.6881, acc is 8.94%
[2024-09-07 22:39:18 Info] Running test set for epoch number 1 for dataset idx 4 using map
[2024-09-07 22:39:18 Info] Stats for test [map] set of size 10000, loss is 2.8674, acc is 8.89%
[2024-09-07 22:39:18 Info] Average accuracy over all tasks for epoch number 1 for dataset idx 4 using map is 11.344
[2024-09-07 22:39:18 Info] Finished epoch number 1, Took 16 seconds
Round - 1,Client - 1
837, 0, 837
[2024-09-07 22:39:18 Info] Inference method: {'map'}
[2024-09-07 22:39:18 Info] Number of parameters in the model is 199,210
[2024-09-07 22:39:18 Info] Criterion parameters: type=<class 'torch.nn.modules.loss.CrossEntropyLoss'>
[2024-09-07 22:39:18 Info] BGD params: {'mean_eta': 3.0, 'std_init': 0.05, 'mc_iters': 10, 'alpha_mg': 0.1}
It's here in new bgd optimizer
[2024-09-07 22:39:18 Info] Gradient clipping with max_norm being done
Model id is  139714482699792
Model value at client 2 is 19.580320358276367 in round 1
[2024-09-07 22:39:18 Info] Training epoch number 1 with dataset number 0
[2024-09-07 22:39:29 Info] Client id 1, Epoch 1, train set, Iter 500 current average loss 0.7943
[2024-09-07 22:39:35 Info] Running test set for epoch number 1 for dataset idx 0 using map
[2024-09-07 22:39:35 Info] Stats for test [map] set of size 10000, loss is 2.6009, acc is 13.7%
[2024-09-07 22:39:35 Info] Running test set for epoch number 1 for dataset idx 1 using map
[2024-09-07 22:39:36 Info] Stats for test [map] set of size 10000, loss is 6.0941, acc is 9.58%
[2024-09-07 22:39:36 Info] Running test set for epoch number 1 for dataset idx 2 using map
[2024-09-07 22:39:36 Info] Stats for test [map] set of size 10000, loss is 3.3395, acc is 9.58%
[2024-09-07 22:39:36 Info] Running test set for epoch number 1 for dataset idx 3 using map
[2024-09-07 22:39:37 Info] Stats for test [map] set of size 10000, loss is 3.2699, acc is 9.58%
[2024-09-07 22:39:37 Info] Running test set for epoch number 1 for dataset idx 4 using map
[2024-09-07 22:39:38 Info] Stats for test [map] set of size 10000, loss is 3.7321, acc is 9.58%
[2024-09-07 22:39:38 Info] Average accuracy over all tasks for epoch number 1 for dataset idx 4 using map is 10.404
[2024-09-07 22:39:38 Info] Finished epoch number 1, Took 19 seconds
Round - 1,Client - 2
837, 0, 837
[2024-09-07 22:39:38 Info] Inference method: {'map'}
[2024-09-07 22:39:38 Info] Number of parameters in the model is 199,210
[2024-09-07 22:39:38 Info] Criterion parameters: type=<class 'torch.nn.modules.loss.CrossEntropyLoss'>
[2024-09-07 22:39:38 Info] BGD params: {'mean_eta': 3.0, 'std_init': 0.05, 'mc_iters': 10, 'alpha_mg': 0.1}
It's here in new bgd optimizer
[2024-09-07 22:39:38 Info] Gradient clipping with max_norm being done
Model id is  139714134234064
Model value at client 3 is 19.580320358276367 in round 1
[2024-09-07 22:39:38 Info] Training epoch number 1 with dataset number 0
[2024-09-07 22:39:47 Info] Client id 2, Epoch 1, train set, Iter 500 current average loss 0.4201
[2024-09-07 22:39:53 Info] Running test set for epoch number 1 for dataset idx 0 using map
[2024-09-07 22:39:53 Info] Stats for test [map] set of size 10000, loss is 2.4811, acc is 10.53%
[2024-09-07 22:39:53 Info] Running test set for epoch number 1 for dataset idx 1 using map
[2024-09-07 22:39:54 Info] Stats for test [map] set of size 10000, loss is 4.1667, acc is 22.31%
[2024-09-07 22:39:54 Info] Running test set for epoch number 1 for dataset idx 2 using map
[2024-09-07 22:39:54 Info] Stats for test [map] set of size 10000, loss is 2.8936, acc is 9.59%
[2024-09-07 22:39:54 Info] Running test set for epoch number 1 for dataset idx 3 using map
[2024-09-07 22:39:55 Info] Stats for test [map] set of size 10000, loss is 2.7555, acc is 10.09%
[2024-09-07 22:39:55 Info] Running test set for epoch number 1 for dataset idx 4 using map
[2024-09-07 22:39:56 Info] Stats for test [map] set of size 10000, loss is 2.9999, acc is 9.68%
[2024-09-07 22:39:56 Info] Average accuracy over all tasks for epoch number 1 for dataset idx 4 using map is 12.44
[2024-09-07 22:39:56 Info] Finished epoch number 1, Took 18 seconds
Round - 1,Client - 3
837, 0, 837
[2024-09-07 22:39:56 Info] Inference method: {'map'}
[2024-09-07 22:39:56 Info] Number of parameters in the model is 199,210
[2024-09-07 22:39:56 Info] Criterion parameters: type=<class 'torch.nn.modules.loss.CrossEntropyLoss'>
[2024-09-07 22:39:56 Info] BGD params: {'mean_eta': 3.0, 'std_init': 0.05, 'mc_iters': 10, 'alpha_mg': 0.1}
It's here in new bgd optimizer
[2024-09-07 22:39:56 Info] Gradient clipping with max_norm being done
Model id is  139714764203728
Model value at client 4 is 19.580320358276367 in round 1
[2024-09-07 22:39:56 Info] Training epoch number 1 with dataset number 0
[2024-09-07 22:40:06 Info] Client id 3, Epoch 1, train set, Iter 500 current average loss 0.5886
[2024-09-07 22:40:12 Info] Running test set for epoch number 1 for dataset idx 0 using map
[2024-09-07 22:40:13 Info] Stats for test [map] set of size 10000, loss is 2.6238, acc is 12.35%
[2024-09-07 22:40:13 Info] Running test set for epoch number 1 for dataset idx 1 using map
[2024-09-07 22:40:14 Info] Stats for test [map] set of size 10000, loss is 3.2924, acc is 27.42%
[2024-09-07 22:40:14 Info] Running test set for epoch number 1 for dataset idx 2 using map
[2024-09-07 22:40:14 Info] Stats for test [map] set of size 10000, loss is 2.8231, acc is 9.31%
[2024-09-07 22:40:14 Info] Running test set for epoch number 1 for dataset idx 3 using map
[2024-09-07 22:40:15 Info] Stats for test [map] set of size 10000, loss is 2.7921, acc is 10.05%
[2024-09-07 22:40:15 Info] Running test set for epoch number 1 for dataset idx 4 using map
[2024-09-07 22:40:15 Info] Stats for test [map] set of size 10000, loss is 2.9812, acc is 9.28%
[2024-09-07 22:40:15 Info] Average accuracy over all tasks for epoch number 1 for dataset idx 4 using map is 13.682
[2024-09-07 22:40:15 Info] Finished epoch number 1, Took 19 seconds
Round - 1,Client - 4
837, 0, 837
[2024-09-07 22:40:15 Info] Inference method: {'map'}
[2024-09-07 22:40:15 Info] Number of parameters in the model is 199,210
[2024-09-07 22:40:15 Info] Criterion parameters: type=<class 'torch.nn.modules.loss.CrossEntropyLoss'>
[2024-09-07 22:40:15 Info] BGD params: {'mean_eta': 3.0, 'std_init': 0.05, 'mc_iters': 10, 'alpha_mg': 0.1}
It's here in new bgd optimizer
[2024-09-07 22:40:15 Info] Gradient clipping with max_norm being done
Model id is  139714482706256
Model value at client 5 is 19.580320358276367 in round 1
[2024-09-07 22:40:15 Info] Training epoch number 1 with dataset number 0
[2024-09-07 22:40:26 Info] Client id 4, Epoch 1, train set, Iter 500 current average loss 0.2976
[2024-09-07 22:40:32 Info] Running test set for epoch number 1 for dataset idx 0 using map
[2024-09-07 22:40:33 Info] Stats for test [map] set of size 10000, loss is 2.4795, acc is 13.26%
[2024-09-07 22:40:33 Info] Running test set for epoch number 1 for dataset idx 1 using map
[2024-09-07 22:40:34 Info] Stats for test [map] set of size 10000, loss is 3.5214, acc is 22.2%
[2024-09-07 22:40:34 Info] Running test set for epoch number 1 for dataset idx 2 using map
[2024-09-07 22:40:34 Info] Stats for test [map] set of size 10000, loss is 2.7881, acc is 12.12%
[2024-09-07 22:40:34 Info] Running test set for epoch number 1 for dataset idx 3 using map
[2024-09-07 22:40:35 Info] Stats for test [map] set of size 10000, loss is 2.5648, acc is 13.49%
[2024-09-07 22:40:35 Info] Running test set for epoch number 1 for dataset idx 4 using map
[2024-09-07 22:40:35 Info] Stats for test [map] set of size 10000, loss is 2.9119, acc is 12.77%
[2024-09-07 22:40:35 Info] Average accuracy over all tasks for epoch number 1 for dataset idx 4 using map is 14.768
[2024-09-07 22:40:35 Info] Finished epoch number 1, Took 19 seconds
Round - 1,Client - 5
837, 0, 837
[2024-09-07 22:40:36 Info] Task wise accuracies after round 1 are [8.92]
[2024-09-07 22:40:36 Info] Client 0 task-wise loss and accuracies are - ([2.729], [8.92])
[2024-09-07 22:40:36 Info] Task wise accuracies after round 1 are [13.7]
[2024-09-07 22:40:36 Info] Client 1 task-wise loss and accuracies are - ([2.601], [13.7])
[2024-09-07 22:40:37 Info] Task wise accuracies after round 1 are [10.53]
[2024-09-07 22:40:37 Info] Client 2 task-wise loss and accuracies are - ([2.483], [10.53])
[2024-09-07 22:40:38 Info] Task wise accuracies after round 1 are [12.35]
[2024-09-07 22:40:38 Info] Client 3 task-wise loss and accuracies are - ([2.624], [12.35])
[2024-09-07 22:40:38 Info] Task wise accuracies after round 1 are [13.26]
[2024-09-07 22:40:38 Info] Client 4 task-wise loss and accuracies are - ([2.481], [13.26])
[2024-09-07 22:40:39 Info] Task wise accuracies after round 1 are [8.12]
[2024-09-07 22:40:39 Info] Value of server model at round 1 is 2.211845636367798
[2024-09-07 22:40:39 Info] Aggregated model avg acc and avg loss - (8.12, 2.438)
[2024-09-07 22:40:39 Info] Round - 1 complete
1
[2024-09-07 22:40:39 Info] BGD params: {'mean_eta': 3.0, 'std_init': 0.05, 'mc_iters': 10, 'alpha_mg': 0.1}
It's here in new bgd optimizer
[2024-09-07 22:40:39 Info] Gradient clipping with max_norm being done
Model id is  139714981707152
Model value at client 1 is 2.211845636367798 in round 2
[2024-09-07 22:40:39 Info] Training epoch number 2 with dataset number 0
[2024-09-07 22:40:49 Info] Client id 0, Epoch 2, train set, Iter 500 current average loss 1.0131
[2024-09-07 22:40:52 Info] Running test set for epoch number 2 for dataset idx 0 using map
[2024-09-07 22:40:53 Info] Stats for test [map] set of size 10000, loss is 2.3993, acc is 14.06%
[2024-09-07 22:40:53 Info] Running test set for epoch number 2 for dataset idx 1 using map
[2024-09-07 22:40:53 Info] Stats for test [map] set of size 10000, loss is 2.1025, acc is 22.88%
[2024-09-07 22:40:53 Info] Running test set for epoch number 2 for dataset idx 2 using map
[2024-09-07 22:40:54 Info] Stats for test [map] set of size 10000, loss is 2.6782, acc is 18.36%
[2024-09-07 22:40:54 Info] Running test set for epoch number 2 for dataset idx 3 using map
[2024-09-07 22:40:55 Info] Stats for test [map] set of size 10000, loss is 2.5131, acc is 12.34%
[2024-09-07 22:40:55 Info] Running test set for epoch number 2 for dataset idx 4 using map
[2024-09-07 22:40:55 Info] Stats for test [map] set of size 10000, loss is 2.6067, acc is 13.37%
[2024-09-07 22:40:55 Info] Average accuracy over all tasks for epoch number 2 for dataset idx 4 using map is 16.202
[2024-09-07 22:40:55 Info] Finished epoch number 2, Took 16 seconds
Round - 2,Client - 1
1507, 837, 1507
[2024-09-07 22:40:55 Info] BGD params: {'mean_eta': 3.0, 'std_init': 0.05, 'mc_iters': 10, 'alpha_mg': 0.1}
It's here in new bgd optimizer
[2024-09-07 22:40:55 Info] Gradient clipping with max_norm being done
Model id is  139714890421264
Model value at client 2 is 2.211845636367798 in round 2
[2024-09-07 22:40:55 Info] Training epoch number 2 with dataset number 0
[2024-09-07 22:41:06 Info] Client id 1, Epoch 2, train set, Iter 500 current average loss 0.088
[2024-09-07 22:41:09 Info] Running test set for epoch number 2 for dataset idx 0 using map
[2024-09-07 22:41:09 Info] Stats for test [map] set of size 10000, loss is 2.8621, acc is 10.32%
[2024-09-07 22:41:09 Info] Running test set for epoch number 2 for dataset idx 1 using map
[2024-09-07 22:41:10 Info] Stats for test [map] set of size 10000, loss is 2.3239, acc is 15.7%
[2024-09-07 22:41:10 Info] Running test set for epoch number 2 for dataset idx 2 using map
[2024-09-07 22:41:11 Info] Stats for test [map] set of size 10000, loss is 3.2206, acc is 23.28%
[2024-09-07 22:41:11 Info] Running test set for epoch number 2 for dataset idx 3 using map
[2024-09-07 22:41:11 Info] Stats for test [map] set of size 10000, loss is 2.99, acc is 10.32%
[2024-09-07 22:41:11 Info] Running test set for epoch number 2 for dataset idx 4 using map
[2024-09-07 22:41:12 Info] Stats for test [map] set of size 10000, loss is 3.0009, acc is 10.32%
[2024-09-07 22:41:12 Info] Average accuracy over all tasks for epoch number 2 for dataset idx 4 using map is 13.988
[2024-09-07 22:41:12 Info] Finished epoch number 2, Took 16 seconds
Round - 2,Client - 2
1507, 837, 1507
[2024-09-07 22:41:12 Info] BGD params: {'mean_eta': 3.0, 'std_init': 0.05, 'mc_iters': 10, 'alpha_mg': 0.1}
It's here in new bgd optimizer
[2024-09-07 22:41:12 Info] Gradient clipping with max_norm being done
Model id is  139714991576144
Model value at client 3 is 2.211845636367798 in round 2
[2024-09-07 22:41:12 Info] Training epoch number 2 with dataset number 0
