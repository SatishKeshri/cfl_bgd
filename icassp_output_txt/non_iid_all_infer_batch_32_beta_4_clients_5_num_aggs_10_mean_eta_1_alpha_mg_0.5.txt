[2024-09-06 13:15:26 Info] Script args: Namespace(dataset='ds_cont_permuted_mnist', nn_arch='mnist_simple_net_200width_domainlearning_784input_10cls_1ds', logname='continous_permuted_mnist_5_tasks', results_dir='ds_cont_permuted_mnist_5_tasks_150_epochs_alpha_0.01_data_type_non_iid_1.0_mean_eta__bgd_new_update_optim_4_beta_with_grad_clip_18:45_06-09-2024', seed=1000, num_workers=1, num_epochs=150, batch_size=32, pruning_percents=[], train_mc_iters=10, std_init=0.05, mean_eta=1.0, permanent_prune_on_epoch=-1, permanent_prune_on_epoch_percent=90, momentum=0.9, lr=0.01, weight_decay=0.0005, test_freq=1, contpermuted_beta=4, optimizer='bgd_new_update', optimizer_params='{}', inference_mc=False, inference_map=True, inference_committee=False, inference_aggsoftmax=False, inference_initstd=False, committee_size=0, test_mc_iters=0, init_params=['{"bias_type":', '"xavier",', '"conv_type":', '"xavier",', '"bn_init":', '"01"}'], desc='', bw_to_rgb=False, permuted_offset=False, labels_trick=False, num_of_permutations=4, iterations_per_virtual_epc=469, separate_labels_space=False, permute_seed=2019, federated_learning=True, n_clients=5, num_aggs_per_task=10, grad_clip=True, max_grad_norm=1.0, non_iid_split=True, alpha=0.01, alpha_mg=0.5)
[2024-09-06 13:15:26 Info] Computer name: iiitd with pytorch version: 2.0.1
Dataset is  ds_cont_permuted_mnist
[2024-09-06 13:15:26 Info] Arguments are Namespace(dataset='ds_cont_permuted_mnist', nn_arch='mnist_simple_net_200width_domainlearning_784input_10cls_1ds', logname='continous_permuted_mnist_5_tasks', results_dir='ds_cont_permuted_mnist_5_tasks_150_epochs_alpha_0.01_data_type_non_iid_1.0_mean_eta__bgd_new_update_optim_4_beta_with_grad_clip_18:45_06-09-2024', seed=1000, num_workers=1, num_epochs=150, batch_size=32, pruning_percents=[], train_mc_iters=10, std_init=0.05, mean_eta=1.0, permanent_prune_on_epoch=-1, permanent_prune_on_epoch_percent=90, momentum=0.9, lr=0.01, weight_decay=0.0005, test_freq=1, contpermuted_beta=4, optimizer='bgd_new_update', optimizer_params='{}', inference_mc=False, inference_map=True, inference_committee=False, inference_aggsoftmax=False, inference_initstd=False, committee_size=0, test_mc_iters=0, init_params=['{"bias_type":', '"xavier",', '"conv_type":', '"xavier",', '"bn_init":', '"01"}'], desc='', bw_to_rgb=False, permuted_offset=False, labels_trick=False, num_of_permutations=4, iterations_per_virtual_epc=469, separate_labels_space=False, permute_seed=2019, federated_learning=True, n_clients=5, num_aggs_per_task=10, grad_clip=True, max_grad_norm=1.0, non_iid_split=True, alpha=0.01, alpha_mg=0.5)
round_end_iters list [ 1758  3517  5276  7034  8793 10552 12310 14069 15828 17587 18994 20401
 21808 23215 24622 26029 27436 28843 30250 31657 33064 34471 35878 37285
 38692 40099 41506 42913 44320 45727 47134 48541 49948 51355 52762 54169
 55576 56983 58390 59797 60852 61907 62962 64018 65073 66128 67184 68239
 69294 70350]
[ 1758  3517  5276  7034  8793 10552 12310 14069 15828 17587 18994 20401
 21808 23215 24622 26029 27436 28843 30250 31657 33064 34471 35878 37285
 38692 40099 41506 42913 44320 45727 47134 48541 49948 51355 52762 54169
 55576 56983 58390 59797 60852 61907 62962 64018 65073 66128 67184 68239
 69294 70350]
50
Client Indices Generation starts
Non-IID split is happening and alpha is 0.01
Non-IID split is happening and alpha is 0.01
Non-IID split is happening and alpha is 0.01
Non-IID split is happening and alpha is 0.01
Non-IID split is happening and alpha is 0.01
Clients Indices Generation ends
Client Indices Generation took 112.7858521938324 seconds
10
[2024-09-06 13:17:20 Info] Transformed model to CUDA
[2024-09-06 13:17:20 Info] Initialized 0 Conv2d layers using nn.init.xavier_normal_
[2024-09-06 13:17:20 Info] Initialized 3 linear layers using xavier
[2024-09-06 13:17:20 Info] Initialized 0 bias conv2d layers using nn.init.xavier.noraml_
[2024-09-06 13:17:20 Info] Initialized 3 bias linear layers using xavier
[2024-09-06 13:17:20 Info] Initialized 0 BN layers using weight=1 and bias=0
[2024-09-06 13:17:20 Info] BGD params: {'mean_eta': 1.0, 'std_init': 0.05, 'mc_iters': 10, 'alpha_mg': 0.5}
It's here in new bgd optimizer
0
[2024-09-06 13:17:20 Info] Inference method: {'map'}
[2024-09-06 13:17:20 Info] Number of parameters in the model is 199,210
[2024-09-06 13:17:20 Info] Criterion parameters: type=<class 'torch.nn.modules.loss.CrossEntropyLoss'>
[2024-09-06 13:17:20 Info] BGD params: {'mean_eta': 1.0, 'std_init': 0.05, 'mc_iters': 10, 'alpha_mg': 0.5}
It's here in new bgd optimizer
[2024-09-06 13:17:20 Info] Gradient clipping with max_norm being done
Model id is  139914884118544
Model value at client 1 is 19.580320358276367 in round 1
[2024-09-06 13:17:20 Info] Training epoch number 1 with dataset number 0
[2024-09-06 13:18:02 Info] Client id 0, Epoch 1, train set, Iter 500 current average loss 2.2096
[2024-09-06 13:18:45 Info] Client id 0, Epoch 1, train set, Iter 1000 current average loss 2.2117
[2024-09-06 13:19:27 Info] Client id 0, Epoch 1, train set, Iter 1500 current average loss 2.2136
[2024-09-06 13:19:52 Info] Running test set for epoch number 1 for dataset idx 0 using map
[2024-09-06 13:19:56 Info] Stats for test [map] set of size 10000, loss is 2.3746, acc is 8.24%
[2024-09-06 13:19:56 Info] Running test set for epoch number 1 for dataset idx 1 using map
[2024-09-06 13:20:00 Info] Stats for test [map] set of size 10000, loss is 2.4401, acc is 9.39%
[2024-09-06 13:20:00 Info] Running test set for epoch number 1 for dataset idx 2 using map
[2024-09-06 13:20:05 Info] Stats for test [map] set of size 10000, loss is 2.405, acc is 12.25%
[2024-09-06 13:20:05 Info] Running test set for epoch number 1 for dataset idx 3 using map
[2024-09-06 13:20:10 Info] Stats for test [map] set of size 10000, loss is 2.4012, acc is 10.36%
[2024-09-06 13:20:10 Info] Running test set for epoch number 1 for dataset idx 4 using map
[2024-09-06 13:20:14 Info] Stats for test [map] set of size 10000, loss is 2.4147, acc is 10.97%
[2024-09-06 13:20:14 Info] Average accuracy over all tasks for epoch number 1 for dataset idx 4 using map is 10.242
[2024-09-06 13:20:14 Info] Finished epoch number 1, Took 173 seconds
Round - 1,Client - 1
1758, 0, 1758
[2024-09-06 13:20:14 Info] Inference method: {'map'}
[2024-09-06 13:20:14 Info] Number of parameters in the model is 199,210
[2024-09-06 13:20:14 Info] Criterion parameters: type=<class 'torch.nn.modules.loss.CrossEntropyLoss'>
[2024-09-06 13:20:14 Info] BGD params: {'mean_eta': 1.0, 'std_init': 0.05, 'mc_iters': 10, 'alpha_mg': 0.5}
It's here in new bgd optimizer
[2024-09-06 13:20:14 Info] Gradient clipping with max_norm being done
Model id is  139914734642704
Model value at client 2 is 19.580320358276367 in round 1
[2024-09-06 13:20:14 Info] Training epoch number 1 with dataset number 0
